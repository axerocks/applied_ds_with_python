{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      9  \n",
       "1      84 \n",
       "2      2  \n",
       "3      53 \n",
       "4      28 \n",
       "5      474\n",
       "6      153\n",
       "7      13 \n",
       "8      129\n",
       "9      98 \n",
       "10     111\n",
       "11     225\n",
       "12     31 \n",
       "13     171\n",
       "14     191\n",
       "15     486\n",
       "16     335\n",
       "17     415\n",
       "18     36 \n",
       "19     405\n",
       "20     323\n",
       "21     422\n",
       "22     375\n",
       "23     380\n",
       "24     345\n",
       "25     57 \n",
       "26     481\n",
       "27     436\n",
       "28     104\n",
       "29     299\n",
       "30     162\n",
       "31     154\n",
       "32     402\n",
       "33     95 \n",
       "34     73 \n",
       "35     108\n",
       "36     156\n",
       "37     332\n",
       "38     182\n",
       "39     82 \n",
       "40     351\n",
       "41     278\n",
       "42     214\n",
       "43     155\n",
       "44     223\n",
       "45     473\n",
       "46     49 \n",
       "47     317\n",
       "48     11 \n",
       "49     319\n",
       "50     40 \n",
       "51     418\n",
       "52     165\n",
       "53     370\n",
       "54     382\n",
       "55     3  \n",
       "56     50 \n",
       "57     363\n",
       "58     219\n",
       "59     465\n",
       "60     237\n",
       "61     23 \n",
       "62     342\n",
       "63     204\n",
       "64     258\n",
       "65     315\n",
       "66     27 \n",
       "67     93 \n",
       "68     17 \n",
       "69     488\n",
       "70     303\n",
       "71     283\n",
       "72     395\n",
       "73     309\n",
       "74     419\n",
       "75     123\n",
       "76     19 \n",
       "77     117\n",
       "78     232\n",
       "79     72 \n",
       "80     189\n",
       "81     369\n",
       "82     493\n",
       "83     318\n",
       "84     239\n",
       "85     148\n",
       "86     105\n",
       "87     336\n",
       "88     6  \n",
       "89     200\n",
       "90     81 \n",
       "91     65 \n",
       "92     434\n",
       "93     164\n",
       "94     378\n",
       "95     313\n",
       "96     495\n",
       "97     424\n",
       "98     398\n",
       "99     5  \n",
       "100    254\n",
       "101    296\n",
       "102    75 \n",
       "103    167\n",
       "104    21 \n",
       "105    259\n",
       "106    499\n",
       "107    347\n",
       "108    150\n",
       "109    78 \n",
       "110    340\n",
       "111    441\n",
       "112    361\n",
       "113    267\n",
       "114    221\n",
       "115    466\n",
       "116    39 \n",
       "117    134\n",
       "118    197\n",
       "119    355\n",
       "120    430\n",
       "121    80 \n",
       "122    444\n",
       "123    246\n",
       "124    85 \n",
       "125    215\n",
       "126    263\n",
       "127    74 \n",
       "128    403\n",
       "129    458\n",
       "130    16 \n",
       "131    25 \n",
       "132    127\n",
       "133    454\n",
       "134    70 \n",
       "135    44 \n",
       "136    59 \n",
       "137    103\n",
       "138    112\n",
       "139    429\n",
       "140    88 \n",
       "141    179\n",
       "142    470\n",
       "143    358\n",
       "144    205\n",
       "145    397\n",
       "146    294\n",
       "147    137\n",
       "148    295\n",
       "149    35 \n",
       "150    438\n",
       "151    247\n",
       "152    209\n",
       "153    61 \n",
       "154    107\n",
       "155    285\n",
       "156    175\n",
       "157    99 \n",
       "158    455\n",
       "159    24 \n",
       "160    275\n",
       "161    421\n",
       "162    48 \n",
       "163    426\n",
       "164    489\n",
       "165    136\n",
       "166    30 \n",
       "167    274\n",
       "168    10 \n",
       "169    178\n",
       "170    1  \n",
       "171    447\n",
       "172    280\n",
       "173    185\n",
       "174    228\n",
       "175    135\n",
       "176    69 \n",
       "177    492\n",
       "178    199\n",
       "179    352\n",
       "180    8  \n",
       "181    276\n",
       "182    230\n",
       "183    334\n",
       "184    96 \n",
       "185    38 \n",
       "186    368\n",
       "187    404\n",
       "188    261\n",
       "189    168\n",
       "190    29 \n",
       "191    437\n",
       "192    423\n",
       "193    54 \n",
       "194    284\n",
       "195    485\n",
       "196    68 \n",
       "197    32 \n",
       "198    349\n",
       "199    41 \n",
       "200    63 \n",
       "201    416\n",
       "202    55 \n",
       "203    130\n",
       "204    116\n",
       "205    76 \n",
       "206    462\n",
       "207    330\n",
       "208    37 \n",
       "209    390\n",
       "210    256\n",
       "211    216\n",
       "212    174\n",
       "213    180\n",
       "214    476\n",
       "215    312\n",
       "216    265\n",
       "217    115\n",
       "218    71 \n",
       "219    218\n",
       "220    202\n",
       "221    440\n",
       "222    385\n",
       "223    373\n",
       "224    210\n",
       "225    89 \n",
       "226    149\n",
       "227    26 \n",
       "228    7  \n",
       "229    435\n",
       "230    482\n",
       "231    177\n",
       "232    157\n",
       "233    412\n",
       "234    22 \n",
       "235    194\n",
       "236    14 \n",
       "237    151\n",
       "238    233\n",
       "239    206\n",
       "240    245\n",
       "241    122\n",
       "242    94 \n",
       "243    461\n",
       "244    226\n",
       "245    97 \n",
       "246    91 \n",
       "247    51 \n",
       "248    33 \n",
       "249    453\n",
       "250    67 \n",
       "251    46 \n",
       "252    322\n",
       "253    66 \n",
       "254    399\n",
       "255    487\n",
       "256    138\n",
       "257    62 \n",
       "258    211\n",
       "259    52 \n",
       "260    269\n",
       "261    119\n",
       "262    100\n",
       "263    442\n",
       "264    310\n",
       "265    143\n",
       "266    301\n",
       "267    113\n",
       "268    478\n",
       "269    298\n",
       "270    272\n",
       "271    354\n",
       "272    0  \n",
       "273    249\n",
       "274    192\n",
       "275    86 \n",
       "276    172\n",
       "277    357\n",
       "278    331\n",
       "279    477\n",
       "280    450\n",
       "281    300\n",
       "282    163\n",
       "283    308\n",
       "284    196\n",
       "285    47 \n",
       "286    133\n",
       "287    359\n",
       "288    64 \n",
       "289    42 \n",
       "290    409\n",
       "291    406\n",
       "292    483\n",
       "293    238\n",
       "294    193\n",
       "295    311\n",
       "296    140\n",
       "297    388\n",
       "298    56 \n",
       "299    236\n",
       "300    372\n",
       "301    110\n",
       "302    248\n",
       "303    60 \n",
       "304    181\n",
       "305    203\n",
       "306    326\n",
       "307    90 \n",
       "308    169\n",
       "309    292\n",
       "310    479\n",
       "311    142\n",
       "312    4  \n",
       "313    124\n",
       "314    324\n",
       "315    121\n",
       "316    131\n",
       "317    166\n",
       "318    468\n",
       "319    365\n",
       "320    213\n",
       "321    87 \n",
       "322    353\n",
       "323    101\n",
       "324    333\n",
       "325    114\n",
       "326    459\n",
       "327    45 \n",
       "328    338\n",
       "329    18 \n",
       "330    222\n",
       "331    343\n",
       "332    20 \n",
       "333    224\n",
       "334    12 \n",
       "335    79 \n",
       "336    387\n",
       "337    251\n",
       "338    120\n",
       "339    471\n",
       "340    77 \n",
       "341    376\n",
       "342    432\n",
       "343    327\n",
       "344    384\n",
       "345    321\n",
       "346    212\n",
       "347    407\n",
       "348    266\n",
       "349    145\n",
       "350    201\n",
       "351    456\n",
       "352    305\n",
       "353    260\n",
       "354    420\n",
       "355    329\n",
       "356    392\n",
       "357    417\n",
       "358    190\n",
       "359    158\n",
       "360    443\n",
       "361    83 \n",
       "362    374\n",
       "363    457\n",
       "364    125\n",
       "365    328\n",
       "366    159\n",
       "367    195\n",
       "368    147\n",
       "369    377\n",
       "370    367\n",
       "371    394\n",
       "372    494\n",
       "373    304\n",
       "374    446\n",
       "375    43 \n",
       "376    262\n",
       "377    128\n",
       "378    102\n",
       "379    449\n",
       "380    184\n",
       "381    469\n",
       "382    452\n",
       "383    234\n",
       "384    362\n",
       "385    356\n",
       "386    144\n",
       "387    291\n",
       "388    484\n",
       "389    188\n",
       "390    414\n",
       "391    92 \n",
       "392    350\n",
       "393    241\n",
       "394    306\n",
       "395    425\n",
       "396    281\n",
       "397    207\n",
       "398    126\n",
       "399    302\n",
       "400    146\n",
       "401    451\n",
       "402    498\n",
       "403    339\n",
       "404    250\n",
       "405    344\n",
       "406    346\n",
       "407    348\n",
       "408    496\n",
       "409    106\n",
       "410    118\n",
       "411    270\n",
       "412    433\n",
       "413    307\n",
       "414    173\n",
       "415    314\n",
       "416    410\n",
       "417    490\n",
       "418    252\n",
       "419    391\n",
       "420    277\n",
       "421    325\n",
       "422    264\n",
       "423    289\n",
       "424    160\n",
       "425    341\n",
       "426    132\n",
       "427    428\n",
       "428    337\n",
       "429    445\n",
       "430    497\n",
       "431    187\n",
       "432    183\n",
       "433    396\n",
       "434    271\n",
       "435    293\n",
       "436    400\n",
       "437    360\n",
       "438    297\n",
       "439    491\n",
       "440    371\n",
       "441    389\n",
       "442    386\n",
       "443    288\n",
       "444    379\n",
       "445    268\n",
       "446    472\n",
       "447    273\n",
       "448    287\n",
       "449    448\n",
       "450    176\n",
       "451    411\n",
       "452    408\n",
       "453    364\n",
       "454    242\n",
       "455    58 \n",
       "456    467\n",
       "457    170\n",
       "458    15 \n",
       "459    240\n",
       "460    316\n",
       "461    229\n",
       "462    217\n",
       "463    109\n",
       "464    227\n",
       "465    290\n",
       "466    460\n",
       "467    393\n",
       "468    282\n",
       "469    34 \n",
       "470    220\n",
       "471    208\n",
       "472    243\n",
       "473    139\n",
       "474    320\n",
       "475    383\n",
       "476    244\n",
       "477    286\n",
       "478    480\n",
       "479    431\n",
       "480    279\n",
       "481    198\n",
       "482    381\n",
       "483    463\n",
       "484    366\n",
       "485    439\n",
       "486    255\n",
       "487    401\n",
       "488    475\n",
       "489    257\n",
       "490    152\n",
       "491    235\n",
       "492    464\n",
       "493    253\n",
       "494    427\n",
       "495    231\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Name: orig_index, dtype: int64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def date_sorter():\n",
    "    \n",
    "    doc = []\n",
    "    with open('dates.txt') as file:\n",
    "        for line in file:\n",
    "            doc.append(line)\n",
    "\n",
    "    df = pd.Series(doc)\n",
    "\n",
    "    df = df.to_frame()\n",
    "    df['orig_index'] = df.index\n",
    "    df.columns = ['text','orig_index']\n",
    "    #df.head(10)\n",
    "    \n",
    "    # Mapping for month to integer\n",
    "    d = {'JAN':1, 'FEB':2, 'MAR':3, 'APR':4, 'MAY':5, 'JUN':6, 'JUL':7, 'AUG':8, 'SEP':9, 'OCT':10, 'NOV':11, 'DEC':12,\n",
    "        'JANUARY':1,'FEBRUARY':2, 'MARCH':3, 'APRIL':4, 'JUNE':6, 'JULY':7, 'AUGUST':8, 'SEPTEMBER':9, 'OCTOBER':10, \n",
    "         'NOVEMBER':11, 'DECEMBER':12, 'DECEMEBER':12, 'JANAURY':1}\n",
    "    \n",
    "    #### extract the strings in format month day year with month in digits\n",
    "    dates_1 = df.text.str.extractall(r'((?P<month>\\d{1,2})[-\\/](?P<day>\\d{1,2})[/\\-](?P<year>\\d{2,4}))')\n",
    "    dates_1['month'] = dates_1['month'].apply('{:0>2}'.format) \n",
    "    dates_1['day'] = dates_1['day'].apply('{:0>2}'.format)\n",
    "    dates_1['year'] = np.where(dates_1['year'].str.len()==2, '19' + dates_1['year'],dates_1['year'])\n",
    "    dates_1.reset_index(inplace=True)\n",
    "    dates_1['orig_index'] = dates_1['level_0']\n",
    "    \n",
    "    # get the remaining dates\n",
    "    dates_1['identified'] = 1\n",
    "    dates_merge = dates_1[['orig_index','identified']]\n",
    "    remaining_text = pd.merge(df,dates_merge,how='outer', on = 'orig_index')\n",
    "    remaining_text = remaining_text[remaining_text['identified'] != 1 ]\n",
    "    remaining_text.index = remaining_text['orig_index']\n",
    "    del remaining_text['identified']\n",
    "    \n",
    "    \n",
    "    #### extract the strings in format day month year with month in words\n",
    "    dates_2 = remaining_text.text.str.extractall(r'((\\d{1,2}) ((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*) (\\d{4}))')\n",
    "    dates_2.columns = ['0','day','month','year']\n",
    "    dates_2['month'] = dates_2['month'].str.upper()\n",
    "    dates_2['month'] = dates_2['month'].map(d)\n",
    "    dates_2['month'] = dates_2['month'].astype(str)\n",
    "    dates_2['month'] = np.where(dates_2['month'].str.len()==1, '0' + dates_2['month'],dates_2['month'])\n",
    "    dates_2['day'] = dates_2['day'].fillna('01')\n",
    "    dates_2.reset_index(inplace=True)\n",
    "    \n",
    "    # get the remaining dates\n",
    "    dates_2['identified'] = 1\n",
    "    dates_merge = dates_2[['orig_index','identified']]\n",
    "    remaining_text = pd.merge(remaining_text,dates_merge,how='outer', on = 'orig_index')\n",
    "    remaining_text = remaining_text[remaining_text['identified'] != 1 ]\n",
    "    remaining_text.index = remaining_text['orig_index']\n",
    "    del remaining_text['identified']\n",
    "    \n",
    "    #### Get the rows that take the form month then day then four digit year\n",
    "    dates_3 = remaining_text.text.str.extractall(r'(((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*)[?:.,]* (\\d{1,2})[?:.,]* (\\d{4}))')\n",
    "    dates_3.columns = ['0','month','day','year']\n",
    "    dates_3['month'] = dates_3['month'].str.upper()\n",
    "    dates_3['month'] = dates_3['month'].map(d)\n",
    "    dates_3['month'] = dates_3['month'].astype(str)\n",
    "    dates_3['month'] = np.where(dates_3['month'].str.len()==1, '0' + dates_3['month'],dates_3['month'])\n",
    "    dates_3.reset_index(inplace=True)\n",
    "    \n",
    "    dates_3['identified'] = 1\n",
    "    dates_merge = dates_3[['orig_index','identified']]\n",
    "    remaining_text = pd.merge(remaining_text,dates_merge,how='outer', on = 'orig_index')\n",
    "    remaining_text = remaining_text[remaining_text['identified'] != 1 ]\n",
    "    remaining_text.index = remaining_text['orig_index']\n",
    "    del remaining_text['identified']\n",
    "    \n",
    "    #### Get the rows that have only a month and a year\n",
    "    dates_4 = remaining_text.text.str.extractall(r'(((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*)[?:.,]* (\\d{4}))')\n",
    "    dates_4.columns = ['0','month','year']\n",
    "    dates_4['month'] = dates_4['month'].str.upper()\n",
    "    dates_4['month'] = dates_4['month'].map(d)\n",
    "    dates_4['month'] = dates_4['month'].astype(str)\n",
    "    dates_4['month'] = np.where(dates_4['month'].str.len()==1, '0' + dates_4['month'],dates_4['month'])\n",
    "    dates_4['day'] = '01'\n",
    "    dates_4.reset_index(inplace=True)\n",
    "    \n",
    "    dates_4['identified'] = 1\n",
    "    dates_merge = dates_4[['orig_index','identified']]\n",
    "    remaining_text = pd.merge(remaining_text,dates_merge,how='outer', on = 'orig_index')\n",
    "    remaining_text = remaining_text[remaining_text['identified'] != 1 ]\n",
    "    remaining_text.index = remaining_text['orig_index']\n",
    "    del remaining_text['identified']\n",
    "    \n",
    "    #### Get the rows that have only a month and year in the format mm/yyyy\n",
    "    dates_5 = remaining_text.text.str.extractall(r'((\\d{1,2})[/](\\d{4}))')\n",
    "    dates_5.columns = ['0','month','year']\n",
    "    dates_5['month'] = dates_5['month'].astype(str)\n",
    "    dates_5['month'] = np.where(dates_5['month'].str.len()==1, '0' + dates_5['month'],dates_5['month'])\n",
    "    dates_5['day'] = '01'\n",
    "    dates_5.reset_index(inplace=True)\n",
    "    dates_5['identified'] = 1\n",
    "    \n",
    "    dates_merge = dates_5[['orig_index','identified']]\n",
    "    remaining_text = pd.merge(remaining_text,dates_merge,how='outer', on = 'orig_index')\n",
    "    remaining_text = remaining_text[remaining_text['identified'] != 1 ]\n",
    "    remaining_text.index = remaining_text['orig_index']\n",
    "    del remaining_text['identified']\n",
    "    \n",
    "    #### Everything that is left should be year only\n",
    "    dates_6 = remaining_text.text.str.extractall(r'((\\d{4}))')\n",
    "    dates_6.columns = ['0','year']\n",
    "    dates_6['day'] = '01'\n",
    "    dates_6['month'] = '01'\n",
    "    dates_6.reset_index(inplace=True)\n",
    "    dates_6['identified'] = 1\n",
    "    \n",
    "    dates_merge = dates_6[['orig_index','identified']]\n",
    "    remaining_text = pd.merge(remaining_text,dates_merge,how='outer', on = 'orig_index')\n",
    "    remaining_text = remaining_text[remaining_text['identified'] != 1 ]\n",
    "    remaining_text.index = remaining_text['orig_index']\n",
    "    del remaining_text['identified']\n",
    "    \n",
    "    frames = [dates_1,dates_2,dates_3,dates_4,dates_5,dates_6]\n",
    "    parsed_dates = pd.concat(frames)\n",
    "    parsed_dates = parsed_dates.sort_values(by=['orig_index'])\n",
    "    parsed_dates.reset_index(inplace=True)\n",
    "    \n",
    "    parsed_dates = parsed_dates.drop(parsed_dates.index[[73]])\n",
    "    \n",
    "    parsed_dates['final_date'] = parsed_dates['month'] + '/' + parsed_dates['day'] + '/' + parsed_dates['year']\n",
    "    parsed_dates['final_date'] = pd.to_datetime(parsed_dates['final_date'])\n",
    "    \n",
    "    parsed_dates = parsed_dates.sort_values(by=['final_date'])\n",
    "    parsed_dates = parsed_dates.drop('level_0',axis = 1)\n",
    "    parsed_dates.reset_index(inplace=True)\n",
    "    \n",
    "    final_out = parsed_dates['orig_index']\n",
    "    del final_out.index.name\n",
    "    \n",
    "    return pd.Series(final_out)\n",
    "\n",
    "date_sorter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type Test (Series?): Passed\n",
      "Data Shape Test ((500,)?): Passed\n",
      "Index Values Test (range(500)?): Passed\n",
      "Values Test (0-499): Passed\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
